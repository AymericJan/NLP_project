{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_Project.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qFUClYUKhLK7",
        "outputId": "8e8fccb1-3c38-4348-dd25-e69b4ed6c17a"
      },
      "source": [
        "import re\n",
        "import matplotlib\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "stop_words = set(stopwords.words('english'))\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import scipy as sp\n",
        "from xgboost.sklearn import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "# !unzip train.csv.zip"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6gZ1NPXhd9y"
      },
      "source": [
        "data = pd.read_csv('train.csv')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4L75fm1mhd3O"
      },
      "source": [
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r\"what's\", \"what is \", text)      ### conversion of contraction words to expanded words\n",
        "    text = re.sub(r\"\\'s\", \" \", text)\n",
        "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
        "    text = re.sub(r\"can't\", \"can not \", text)\n",
        "    text = re.sub(r\"n't\", \" not \", text)\n",
        "    text = re.sub(r\"i'm\", \"i am \", text)\n",
        "    text = re.sub(r\"\\'re\", \" are \", text)\n",
        "    text = re.sub(r\"\\'d\", \" would \", text)\n",
        "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
        "    text = re.sub(r\"\\'scuse\", \" excuse \", text)\n",
        "    text = re.sub('\\W', ' ', text)                                                 ### removing non-word characters\n",
        "\n",
        "    text = re.sub(r'fck', 'fuck', text)\n",
        "    text = re.sub(r'a$$', 'ass', text)\n",
        "    text = re.sub(r'@', 'at', text)\n",
        "    text = re.sub(r'wikipedia:[^\\s]+',' ', text)\n",
        "    text = re.sub(r\"https?://[A-Za-z0-9./]+\", ' ', text)\n",
        "    text = re.sub('(utc)', ' ' ,text)\n",
        "    text = re.sub(' u ', ' you ' ,text)\n",
        "\n",
        "\n",
        "    text = re.sub('[^A-Za-z\\' ]+', '',text)                                        ### removing all non-letter values(Except single quotes)\n",
        "    text = re.sub('\\s+', ' ', text)\n",
        "\n",
        "    text = text.strip(' ')\n",
        "    text = ' '.join([word for word in text.split() if word not in (stop_words)])    ### Stopwords removal\n",
        "    return text\n",
        "\n",
        "data[\"comment_text\"] = data[\"comment_text\"].apply(clean_text)\n",
        "train_df, test_df = train_test_split( data, train_size=.85)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JtWvxFlzhdv2"
      },
      "source": [
        "train_data = train_df[\"comment_text\"]\n",
        "test_data = test_df[\"comment_text\"]\n",
        "train_label=train_df[['toxic', 'severe_toxic', 'obscene', 'threat','insult', 'identity_hate']]\n",
        "test_label=test_df[['toxic', 'severe_toxic', 'obscene', 'threat','insult', 'identity_hate']]"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yAst_eSLyi7z"
      },
      "source": [
        "all_data = pd.concat([train_data, test_data])\n",
        "\n",
        "word_vectorizer = TfidfVectorizer(\n",
        "    sublinear_tf=True,\n",
        "    analyzer='word',\n",
        "    ngram_range=(1, 1),\n",
        "    norm='l2',\n",
        "    max_features=15000)\n",
        "word_vectorizer.fit(all_data)\n",
        "train_word_features = word_vectorizer.transform(train_data)\n",
        "test_word_features = word_vectorizer.transform(test_data)\n",
        "\n",
        "char_vectorizer = TfidfVectorizer(\n",
        "    sublinear_tf=True,\n",
        "    analyzer='char',\n",
        "    ngram_range=(1, 5),\n",
        "    norm='l2',\n",
        "    max_features=50000)\n",
        "char_vectorizer.fit(all_data)\n",
        "train_char_features = char_vectorizer.transform(train_data)\n",
        "test_char_features = char_vectorizer.transform(test_data)\n",
        "\n",
        "train_full_feature = sp.sparse.hstack([train_word_features,train_char_features])\n",
        "test_full_feature = sp.sparse.hstack([test_word_features,test_char_features])"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5xg5bTq3Inw",
        "outputId": "82725206-5da0-49a7-b855-249cf14841fa"
      },
      "source": [
        "target_list = test_label.columns\n",
        "acc_list = np.zeros((2,6))\n",
        "for i in range(len(target_list)):\n",
        "  target = target_list[i]\n",
        "  print(target)\n",
        "  model=XGBClassifier(learning_rate=0.01,max_depth= 5, subsample= 0.8,n_estimators=50)\n",
        "  model.fit(train_full_feature,train_label[target])\n",
        "  predict_train = model.predict(train_full_feature)\n",
        "  acc_temp = accuracy_score(predict_train,train_label[target])\n",
        "  print(\"     Train accuracy = \",acc_temp)\n",
        "  acc_list[0,i] = acc_temp\n",
        "  predict_test = model.predict(test_full_feature)\n",
        "  acc_temp = accuracy_score(predict_test,test_label[target])\n",
        "  print(\"     Test accuracy = \",acc_temp)\n",
        "  acc_list[1,i] = acc_temp\n",
        "\n",
        "print(acc_list)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "toxic\n",
            "     Train accuracy =  0.9405155072036899\n",
            "     Test accuracy =  0.9239894963893839\n",
            "severe_toxic\n",
            "     Train accuracy =  0.9913580788489137\n",
            "     Test accuracy =  0.9940291975366532\n",
            "obscene\n",
            "     Train accuracy =  0.9772953732194446\n",
            "     Test accuracy =  0.9568601706836725\n",
            "threat\n",
            "     Train accuracy =  0.9977439509685344\n",
            "     Test accuracy =  0.9965925786989278\n",
            "insult\n",
            "     Train accuracy =  0.9693804012007194\n",
            "     Test accuracy =  0.954812591828441\n",
            "identity_hate\n",
            "     Train accuracy =  0.9930814496368388\n",
            "     Test accuracy =  0.9914970771202601\n",
            "[[0.94051551 0.99135808 0.97729537 0.99774395 0.9693804  0.99308145]\n",
            " [0.9239895  0.9940292  0.95686017 0.99659258 0.95481259 0.99149708]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nOncRjCsPWu_",
        "outputId": "e05a2a23-be1e-4a3c-bb89-c99e619a5a5a"
      },
      "source": [
        "print(\"XGBoost performance \\n\",\"performance on each label :\\n\",acc_list,\"\\n train mean accuracy :\",np.mean(acc_list,axis=1)[0],\"\\n test mean accuracy :\"\n",
        ",np.mean(acc_list,axis=1)[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "XGBoost performance \n",
            " performance on each label :\n",
            " [[0.94051551 0.99135808 0.97729537 0.99774395 0.9693804  0.99308145]\n",
            " [0.9239895  0.9940292  0.95686017 0.99659258 0.95481259 0.99149708]] \n",
            " train mean accuracy : 0.9782291266666667 \n",
            " test mean accuracy : 0.9696301866666666\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NwsR-0ngp_Ag",
        "outputId": "5593c33b-8dc8-4db2-d869-f69d2fcd9d60"
      },
      "source": [
        "target_list = test_label.columns\n",
        "acc_list = np.zeros((2,6))\n",
        "for i in range(len(target_list)):\n",
        "  target = target_list[i]\n",
        "  print(target)\n",
        "  model= LogisticRegression(solver='liblinear',dual=True) \n",
        "  model.fit(train_full_feature,train_label[target])\n",
        "  predict_train = model.predict(train_full_feature)\n",
        "  acc_temp = accuracy_score(predict_train,train_label[target])\n",
        "  print(\"     Train accuracy = \",acc_temp)\n",
        "  acc_list[0,i] = acc_temp\n",
        "  predict_test = model.predict(test_full_feature)\n",
        "  acc_temp = accuracy_score(predict_test,test_label[target])\n",
        "  print(\"     Test accuracy = \",acc_temp)\n",
        "  acc_list[1,i] = acc_temp\n",
        "\n",
        "print(acc_list)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "toxic\n",
            "     Train accuracy =  0.9691451321561544\n",
            "     Test accuracy =  0.9612717245989305\n",
            "severe_toxic\n",
            "     Train accuracy =  0.9919268625354812\n",
            "     Test accuracy =  0.9903492647058824\n",
            "obscene\n",
            "     Train accuracy =  0.9841043978324179\n",
            "     Test accuracy =  0.9799465240641712\n",
            "threat\n",
            "     Train accuracy =  0.9975080178420024\n",
            "     Test accuracy =  0.9974515374331551\n",
            "insult\n",
            "     Train accuracy =  0.977653260589081\n",
            "     Test accuracy =  0.9728442513368984\n",
            "identity_hate\n",
            "     Train accuracy =  0.993615217311166\n",
            "     Test accuracy =  0.9922292780748663\n",
            "[[0.96914513 0.99192686 0.9841044  0.99750802 0.97765326 0.99361522]\n",
            " [0.96127172 0.99034926 0.97994652 0.99745154 0.97284425 0.99222928]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oHsUfWVvBEIL",
        "outputId": "386da253-de2f-4216-dfc9-c80557b0a705"
      },
      "source": [
        "print(\"Logistic regression performance \\n\",\"performance on each label :\\n\",acc_list,\"\\n train mean accuracy :\",np.mean(acc_list,axis=1)[0],\"\\n test mean accuracy :\"\n",
        ",np.mean(acc_list,axis=1)[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Logistic regression performance \n",
            " performance on each label :\n",
            " [[0.96914513 0.99192686 0.9841044  0.99750802 0.97765326 0.99361522]\n",
            " [0.96127172 0.99034926 0.97994652 0.99745154 0.97284425 0.99222928]] \n",
            " train mean accuracy : 0.985658815 \n",
            " test mean accuracy : 0.9823487616666666\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}